{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DIGITS CLASSIFICATION USING SVM AND LOGISTIC REGRESSION\n",
    "\n",
    "The digits dataset contains images of handwritten digits from 0-9. we train our model to be smart enough to recognize the images both seen and unseen images without being explicitly programmed.\n",
    "The dataset comes packaged with sklearn. We will train it on 70% of the data and the rest of the 30% can be saved for testing the accuracy of the model.\n",
    "\n",
    "# # Objective: \n",
    " In this notebook,we will compare the accuracy of two models by training them with different algorithms.\n",
    "\n",
    "we would like to start with logistic regression. The logistic regression gives the probability for the each output and based on that we decide which sample belongs to what class.\n",
    "\n",
    "The Support Vector Machine tries to separte data into different by drawing either a line or curve between them such that the line or curve best separate the data into different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "import pandas as pd\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 47  0  0  0  0  2  0  3  0]\n",
      " [ 0  0 51  2  0  0  0  0  0  0]\n",
      " [ 0  0  1 52  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 48  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 55  1  0  0  0]\n",
      " [ 0  1  0  0  0  0 59  0  0  0]\n",
      " [ 0  1  0  1  1  0  0 50  0  0]\n",
      " [ 0  3  1  0  0  0  0  0 55  2]\n",
      " [ 0  0  0  1  0  1  0  0  2 53]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics                         #Through confusion matrix we can see that how many samples were classified in wrong classes.\n",
    "cm = metrics.confusion_matrix(y_test, predictions)  \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9537037037037037"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_logi = metrics.accuracy_score(y_test, predictions)\n",
    "accuracy_logi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters in SVM:\n",
    "C and gamma are defined by the concepts of \"hard margin\" and \"soft margin\".\n",
    "By using a smaller C we can have our model to generalize better and works well with unseen data. But if we increase C it will be trained well on the available data but won't be able to generalize well.\n",
    "Same is with parameter gamma.\n",
    "we should reduce both if the model is overfitting and increase it if the model is underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl= svm.SVC(gamma= 10, C= 100)\n",
    "cl.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_svm_train=cl.predict(x_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_train = accuracy_score(y_train, pred_svm_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm=cl.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0 52  0  0  0  0  0]\n",
      " [ 0  0  0  0 53  0  0  0  0  0]\n",
      " [ 0  0  0  0 54  0  0  0  0  0]\n",
      " [ 0  0  0  0 48  0  0  0  0  0]\n",
      " [ 0  0  0  0 57  0  0  0  0  0]\n",
      " [ 0  0  0  0 60  0  0  0  0  0]\n",
      " [ 0  0  0  0 53  0  0  0  0  0]\n",
      " [ 0  0  0  0 61  0  0  0  0  0]\n",
      " [ 0  0  0  0 57  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test, pred_svm)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08888888888888889"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the test accuracy is less than train accuracy we should reduce both in oder to make our model generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8481481481481481"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl= svm.SVC(gamma= 0.01, C= 5)\n",
    "cl.fit(x_train, y_train)\n",
    "pred_svm=cl.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_10C = accuracy_score(y_test, pred_svm)\n",
    "accuracy_10C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907407407407407"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl= svm.SVC(gamma= 0.001, C= 5)\n",
    "cl.fit(x_train, y_train)\n",
    "pred_svm=cl.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_10C = accuracy_score(y_test, pred_svm)\n",
    "accuracy_10C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "By comparison, SVM gave more accurate results on test dataset as compared to logistic regression.we just had to regularize the parameters C and  Gamma. 84% is what we got with C =5 an gamma 0.01 but it performed well with gamma 0.001."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
